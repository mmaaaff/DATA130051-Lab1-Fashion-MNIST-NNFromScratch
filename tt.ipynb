{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyDL\n",
    "import MyDL.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = MyDL.MyTensor([[1,2,3], [4,5,6]])\n",
    "b = MyDL.MyTensor([1,2,3])\n",
    "c = b * a\n",
    "d = c.sum()\n",
    "d.backward()\n",
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import MyDL\n",
    "import MyDL.nn as nn\n",
    "import cupy as np\n",
    "X = MyDL.MyTensor(np.random.rand(8, 3, 7, 7))\n",
    "layer_conv = nn.Conv2D(3, 5, 4, 1, 2, False)\n",
    "t = layer_conv(X)\n",
    "print(t.shape)\n",
    "t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1,2,3]\n",
    "\n",
    "a = np.asarray(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cupy\n",
      "12\n",
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n",
      "(10, 10)\n",
      "(10,)\n",
      "(784,)\n",
      "(784,)\n",
      "(100,)\n",
      "(100,)\n",
      "(10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import cupy as np\n",
    "\n",
    "print(np.__name__)\n",
    "\n",
    "with np.load('figure\\model_params\\MLP3_(100,10)_relu_L2-0.0_lr-0.1.npz') as weights:\n",
    "    print(len(weights.npz_file))\n",
    "    for data in weights.npz_file.values():\n",
    "        print(data.shape)\n",
    "\n",
    "dd = {'ds': 1, 'ds2': 2}\n",
    "aa = {k: v for k, v in dd.items() if k == 'ds'}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cupy version: 13.4.1\n",
      "CUDA runtime version: 12080\n",
      "Device properties: {'name': b'NVIDIA GeForce RTX 3060 Laptop GPU', 'totalGlobalMem': 6441926656, 'sharedMemPerBlock': 49152, 'regsPerBlock': 65536, 'warpSize': 32, 'maxThreadsPerBlock': 1024, 'maxThreadsDim': (1024, 1024, 64), 'maxGridSize': (2147483647, 65535, 65535), 'clockRate': 1425000, 'totalConstMem': 65536, 'major': 8, 'minor': 6, 'textureAlignment': 512, 'texturePitchAlignment': 32, 'multiProcessorCount': 30, 'kernelExecTimeoutEnabled': 1, 'integrated': 0, 'canMapHostMemory': 1, 'computeMode': 0, 'maxTexture1D': 131072, 'maxTexture2D': (131072, 65536), 'maxTexture3D': (16384, 16384, 16384), 'concurrentKernels': 1, 'ECCEnabled': 0, 'pciBusID': 1, 'pciDeviceID': 0, 'pciDomainID': 0, 'tccDriver': 0, 'memoryClockRate': 7001000, 'memoryBusWidth': 192, 'l2CacheSize': 3145728, 'maxThreadsPerMultiProcessor': 1536, 'isMultiGpuBoard': 0, 'cooperativeLaunch': 1, 'cooperativeMultiDeviceLaunch': 0, 'deviceOverlap': 1, 'maxTexture1DMipmap': 32768, 'maxTexture1DLinear': 268435456, 'maxTexture1DLayered': (32768, 2048), 'maxTexture2DMipmap': (32768, 32768), 'maxTexture2DLinear': (131072, 65000, 2097120), 'maxTexture2DLayered': (32768, 32768, 2048), 'maxTexture2DGather': (32768, 32768), 'maxTexture3DAlt': (8192, 8192, 32768), 'maxTextureCubemap': 32768, 'maxTextureCubemapLayered': (32768, 2046), 'maxSurface1D': 32768, 'maxSurface1DLayered': (32768, 2048), 'maxSurface2D': (131072, 65536), 'maxSurface2DLayered': (32768, 32768, 2048), 'maxSurface3D': (16384, 16384, 16384), 'maxSurfaceCubemap': 32768, 'maxSurfaceCubemapLayered': (32768, 2046), 'surfaceAlignment': 512, 'asyncEngineCount': 1, 'unifiedAddressing': 1, 'streamPrioritiesSupported': 1, 'globalL1CacheSupported': 1, 'localL1CacheSupported': 1, 'sharedMemPerMultiprocessor': 102400, 'regsPerMultiprocessor': 65536, 'managedMemory': 1, 'multiGpuBoardGroupID': 0, 'hostNativeAtomicSupported': 0, 'singleToDoublePrecisionPerfRatio': 32, 'pageableMemoryAccess': 0, 'concurrentManagedAccess': 0, 'computePreemptionSupported': 1, 'canUseHostPointerForRegisteredMem': 0, 'sharedMemPerBlockOptin': 101376, 'pageableMemoryAccessUsesHostPageTables': 0, 'directManagedMemAccessFromHost': 0, 'uuid': b'\\x8f7\\xe3\\x82wYb.\\x9e\\x98\\xdd\\x0b\\xa1n{\\xd0\\\\\\x9d7\\x03', 'luid': b'\\\\\\x9d7\\x03', 'luidDeviceNodeMask': 1, 'persistingL2CacheMaxSize': 2162688, 'maxBlocksPerMultiProcessor': 16, 'accessPolicyMaxWindowSize': 134213632, 'reservedSharedMemPerBlock': 1024}\n",
      "[[[[ 0  1]\n",
      "   [ 4  5]]\n",
      "\n",
      "  [[ 1  2]\n",
      "   [ 5  6]]]\n",
      "\n",
      "\n",
      " [[[ 4  5]\n",
      "   [ 8  9]]\n",
      "\n",
      "  [[ 5  6]\n",
      "   [ 9 10]]]]\n"
     ]
    }
   ],
   "source": [
    "# x = cp.arange(6).reshape(2, 3).astype('f')\n",
    "# print(x)\n",
    "import os\n",
    "os.add_dll_directory(r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\")\n",
    "import cupy as cp\n",
    "from cupy.lib.stride_tricks import as_strided\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "print(\"CUDA runtime version:\", cp.cuda.runtime.runtimeGetVersion())\n",
    "print(\"Device properties:\", cp.cuda.runtime.getDeviceProperties(0))\n",
    "x = cp.arange(6).reshape(2, 3).astype('f')\n",
    "\n",
    "a = cp.arange(16).reshape(4, 4)\n",
    "view = as_strided(a, shape=(2, 2, 2, 2), strides=(16, 4, 16, 4))\n",
    "print(view)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupyx.lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcupyx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstride_tricks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_strided\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMyDL\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMyDL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cupyx.lib'"
     ]
    }
   ],
   "source": [
    "import cupy as np\n",
    "from cupyx.lib.stride_tricks import as_strided\n",
    "import MyDL\n",
    "import MyDL.nn\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "conv_layer = MyDL.nn.layers.Conv2D(in_channels=3, out_channels=5, kernel_size=4, stride=2, padding=(2, 1, 2, 1), bias=True)\n",
    "\n",
    "X = np.random.rand(8, 3, 7, 7)   # 输入通道 C_in = 3\n",
    "X = MyDL.MyTensor(X)\n",
    "x_out = conv_layer(X)\n",
    "x_out.shape\n",
    "y = x_out.sum()\n",
    "y.backward()\n",
    "\n",
    "\n",
    "print(conv_layer.kernel.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ll(*nums):\n",
    "    print(type(nums))\n",
    "    return nums\n",
    "\n",
    "ll(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3 -4  2  5]\n",
      " [-3 -5  1  7]\n",
      " [-2 -4  0  7]\n",
      " [-1 -2  0  5]]\n"
     ]
    }
   ],
   "source": [
    "# 单通道卷积\n",
    "import cupy as np\n",
    "from cupyx.lib.stride_tricks import as_strided\n",
    "\n",
    "def conv2d_strided(X, K, padding=0, stride=1):\n",
    "    \"\"\"\n",
    "    用 as_strided 实现高效的二维卷积（单通道）\n",
    "    参数：\n",
    "        X : 原始图像 (H, W)\n",
    "        K : 卷积核 (kH, kW)\n",
    "        padding : 填充边界（默认0）\n",
    "        stride : 步幅（默认1）\n",
    "    返回：\n",
    "        Y : 卷积结果\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    K = np.array(K)\n",
    "\n",
    "    H, W = X.shape\n",
    "    kH, kW = K.shape\n",
    "\n",
    "    # 添加 zero-padding\n",
    "    if padding > 0:\n",
    "        X_padded = np.pad(X, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        X_padded = X\n",
    "\n",
    "    H_p, W_p = X_padded.shape\n",
    "\n",
    "    # 输出尺寸\n",
    "    out_h = (H_p - kH) // stride + 1\n",
    "    out_w = (W_p - kW) // stride + 1\n",
    "\n",
    "    # 构造滑动窗口视图：(out_h, out_w, kH, kW)\n",
    "    shape = (out_h, out_w, kH, kW)\n",
    "    strides = (\n",
    "        X_padded.strides[0] * stride,\n",
    "        X_padded.strides[1] * stride,\n",
    "        X_padded.strides[0],\n",
    "        X_padded.strides[1],\n",
    "    )\n",
    "    X_strided = as_strided(X_padded, shape=shape, strides=strides)\n",
    "\n",
    "    # 逐窗口点乘卷积核并求和（向量化）\n",
    "    Y = np.einsum('ijkl,kl->ij', X_strided, K)\n",
    "\n",
    "    return Y\n",
    "\n",
    "X = np.array([\n",
    "    [1, 2, 3, 0],\n",
    "    [0, 1, 2, 1],\n",
    "    [1, 0, 2, 1],\n",
    "    [2, 1, 3, 0]\n",
    "])\n",
    "\n",
    "K = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "Y = conv2d_strided(X, K, padding=1, stride=1)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# 多通道卷积\n",
    "import cupy as np\n",
    "from cupyx.lib.stride_tricks import as_strided\n",
    "\n",
    "def conv2d_multi_channel(X, K, padding=0, stride=1):\n",
    "    \"\"\"\n",
    "    多通道二维卷积实现（无for循环）\n",
    "    参数：\n",
    "        X: 输入图像 (C_in, H, W)\n",
    "        K: 卷积核 (C_out, C_in, kH, kW)\n",
    "        padding: 零填充大小\n",
    "        stride: 步幅\n",
    "    返回：\n",
    "        Y: 输出特征图 (C_out, H_out, W_out)\n",
    "    \"\"\"\n",
    "    C_in, H, W = X.shape\n",
    "    C_out, C_in_k, kH, kW = K.shape\n",
    "    assert C_in == C_in_k, \"卷积核的输入通道数必须等于输入图像的通道数\"\n",
    "\n",
    "    # padding 每个通道\n",
    "    if padding > 0:\n",
    "        X_padded = np.pad(X, ((0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        X_padded = X\n",
    "\n",
    "    H_p, W_p = X_padded.shape[1], X_padded.shape[2]\n",
    "\n",
    "    H_out = (H_p - kH) // stride + 1\n",
    "    W_out = (W_p - kW) // stride + 1\n",
    "\n",
    "    # 滑动窗口展开：输出形状 (C_in, H_out, W_out, kH, kW)\n",
    "    strides = X_padded.strides\n",
    "    new_shape = (C_in, H_out, W_out, kH, kW)\n",
    "    new_strides = (\n",
    "        strides[0],\n",
    "        strides[1] * stride,\n",
    "        strides[2] * stride,\n",
    "        strides[1],\n",
    "        strides[2]\n",
    "    )\n",
    "    X_strided = as_strided(X_padded, shape=new_shape, strides=new_strides)\n",
    "\n",
    "    # 卷积操作：K 是 (C_out, C_in, kH, kW)，X 是 (C_in, H_out, W_out, kH, kW)\n",
    "    # 使用einsum进行高效批量计算\n",
    "    Y = np.einsum('oimn,ihwmn->ohw', K, X_strided)\n",
    "\n",
    "    return Y\n",
    "\n",
    "X = np.random.rand(3, 5, 5)   # 输入通道 C_in = 3\n",
    "K = np.random.rand(4, 3, 3, 3) # 输出通道 C_out = 4，卷积核 3x3\n",
    "\n",
    "Y = conv2d_multi_channel(X, K, padding=1, stride=1)\n",
    "\n",
    "print(Y.shape)  # 应输出 (4, 5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 7, 7)\n",
      "(8, 5, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# 多通道卷积\n",
    "import cupy as np\n",
    "from typing import Union, Tuple\n",
    "from cupyx.lib.stride_tricks import as_strided\n",
    "\n",
    "def conv2d_multi_channel(X, K, padding:Union[int, Tuple[int, int, int, int]]=0, \n",
    "                         stride:Union[int, Tuple[int, int]]=1):\n",
    "    \"\"\"\n",
    "    多通道二维卷积实现（无for循环）\n",
    "    参数：\n",
    "        X: 输入图像 (batch, C_in, H, W)\n",
    "        K: 卷积核 (C_out, C_in, kH, kW)\n",
    "        padding: 零填充大小，整数或元组(up, down, left, right)\n",
    "        stride: 步幅\n",
    "    返回：\n",
    "        Y: 输出特征图 (C_out, H_out, W_out)\n",
    "    \"\"\"\n",
    "\n",
    "    batch, C_in, H, W = X.shape\n",
    "    C_out, C_in_k, kH, kW = K.shape\n",
    "    assert C_in == C_in_k, \"卷积核的输入通道数必须等于输入图像的通道数\"\n",
    "\n",
    "    # padding 每个通道\n",
    "    if isinstance(padding, int):\n",
    "        X_padded = np.pad(X, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    else:\n",
    "        X_padded = np.pad(X, ((0, 0), (0, 0), (padding[0], padding[1]), (padding[2], padding[3])), mode='constant')\n",
    "    \n",
    "    if isinstance(stride, int):\n",
    "        stride = (stride, stride)\n",
    "\n",
    "    H_p, W_p = X_padded.shape[2], X_padded.shape[3]\n",
    "\n",
    "    H_out = (H_p - kH) // stride[0] + 1\n",
    "    W_out = (W_p - kW) // stride[1] + 1\n",
    "\n",
    "    # 滑动窗口展开：输出形状 (C_in, H_out, W_out, kH, kW)\n",
    "    strides = X_padded.strides\n",
    "    new_shape = (batch, C_in, H_out, W_out, kH, kW)\n",
    "    new_strides = (\n",
    "        strides[0],\n",
    "        strides[1],\n",
    "        strides[2] * stride[0],\n",
    "        strides[3] * stride[1],\n",
    "        strides[2],\n",
    "        strides[3]\n",
    "    )\n",
    "    X_strided = as_strided(X_padded, shape=new_shape, strides=new_strides)\n",
    "\n",
    "    # 卷积操作：K 是 (C_out, C_in, kH, kW)，X 是 (batch, C_in, H_out, W_out, kH, kW)\n",
    "    # 使用einsum进行高效批量计算\n",
    "    Y = np.einsum('oimn,bihwmn->bohw', K, X_strided)\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "X = np.random.rand(8, 3, 7, 7)   # 输入通道 C_in = 3\n",
    "K = np.random.rand(5, 3, 4, 4)   # c_in, c_out, kh, kw\n",
    "\n",
    "Y = conv2d_multi_channel(X, K, padding=(2,1,2,1), stride=(2,2))\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)  # 应输出 (8, 4, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0],\n",
       "       [0, 5, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as np\n",
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "a[:, ::2] = 0\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
